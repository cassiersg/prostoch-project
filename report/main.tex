\documentclass[english,DIV=13]{scrreprt}
%\documentclass[english,DIV=13]{scrartcl}

\input{lib.tex}

% Definition to put a bar under a letter/word (to use with matrix)
\usepackage{accents}
\newcommand{\ubar}[1]{\underaccent{\bar}{#1}}
\newcommand{\uvec}[1]{\ubar{#1}}
\newcommand{\umatrix}[1]{\ubar{\ubar{#1}}}

\titlehead{}
\subject{LINMA 1731 --- Stochastic processes}
\title{Bearings-only tracking problem}
\subtitle{}
\author{\begin{tabular}{cc}
	\textsc{Cassiers} Gaëtan  & 	$33741300$ \\
	\textsc{Losseau} Bruno 	&	$33741300$
	 \end{tabular}}
\date{\today}
\publishers{}

\begin{document}
\maketitle


\tableofcontents


%Q1
\chapter{Basics}
\section*{Deriving $\umatrix{F}$ and $\uvec{U}$}

We start by studying the making a discretization of a movemement process in 1D, with the
variable $x(t)$. If we denote $x_k = x(Tk)$ (with $T$ a given discretization step), we
get
\begin{align*}
    x_{k+1} &= x_k + T\dot{x}_k + \int_{Tk}^{T(k+1)}\int_{Tk}^{t}\ddot{x}(t)\dif t\dif t' \\
    \dot{x}_{k+1} &=  \dot{x}_k + \int_{Tk}^{T(k+1)}\ddot{x}(t)\dif t.
\end{align*}
This is a simple discrete-time state model, if we consider that the terms which depends of
the integral of $\ddot{x}$
are an input signal.
We can generalize this equation to the relative state vector $\uvec{x} = \uvec{x}^t - \uvec{x}^o$:
\[\uvec{x}_{k+1} = \umatrix{F}\uvec{x}_k - \uvec{U}_{k,k+1} + \uvec{\epsilon}_k\]
with
\begin{itemize}
    \item The matrix
        \[\umatrix{F} =
        \begin{pmatrix}
            1 & 0 & T & 0 \\
            0 & 1 & 0 & T \\   
            0 & 0 & 1 & 0 \\
            0 & 0 & 0 & 1   
        \end{pmatrix}
        \]
    \item $\uvec{\epsilon}_k$ the variation of position and of velocity of the target caused by the
acceleration of the target,
    \item $\uvec{U}_{k,k+1}$ the variation of position and velocity of
the observer caused by the acceleration of the observer.
\end{itemize}

\section*{Deriving $h(\ubar{x})$}
Following its definition given in the statement and using the notation $\uvec{x}(i)$
for the $i$-th element of the vector $\uvec{x}$:
\begin{align*}
    h(\uvec{x}_k) &= \mathrm{atan2}(\uvec{x}_k(1), \uvec{x}_k(2)) \\
    &= \begin{cases}
        \arctan\frac{\uvec{x}_k(1)}{\uvec{x}_k(2)} & \text{if $\uvec{x}_k(2) > 0$} \\
        \arctan\frac{\uvec{x}_k(1)}{\uvec{x}_k(2)}+\pi & \text{if $\uvec{x}_k(2) < 0$ and $\uvec{x}_k(1) \geq 0$} \\
        \arctan\frac{\uvec{x}_k(1)}{\uvec{x}_k(2)}-\pi & \text{if $\uvec{x}_k(2) < 0$ and $\uvec{x}_k(1) < 0$} \\
        0 & \text{if $\uvec{x}_k(2) \geq 0$ and $\uvec{x}_k(1) = 0$} \\
        \pi & \text{if $\uvec{x}_k(2) < 0$ and $\uvec{x}_k(1) = 0$}
    \end{cases}
\end{align*}

%Q2
\chapter{Simple model}
At first, without implementing any command, it is asked to simulate the system for $k=200$ steps, changing
the values of the variance $\sigma^2_{\theta}$ of the gausian noise on the bearing $w_k$  and
the variance  $\sigma^2_a$ of the gausian noise on the acceleration $\epsilon_k$.

\section*{Code}
For each chapter, one only presents the code that is strictly relevant. The scripts and functions 
used to plot the required results (herein \texttt{plot\_q2.m} and \texttt{gen\_plot2.m})
can be found in the linked archive. To obtain the results for all the questions, simply launch
the script \texttt{main.m}.\\

\lstinputlisting[caption={Simulating the system}]{../matlab/q2.m}

Every time a code uses a parameter given in the statement, it calls the following function : 
\lstinputlisting[caption={Parameters given in the statement}]{../matlab/gen_parameters.m}

\section*{Results}
\begin{itemize}
\item varying $\sigma_\theta$ with $\sigma_a=0$
\begin{center}	
\includegraphics[width=0.66\textwidth]{img/q2_1.eps}
\end{center}
When there is no noise, one verifies that as the relative velocity is constant and there is no error on
the bearing, the angle is constant and the the relative position is linear.\\
As the acceleration is by default equal to zero and that there is no noise on the acceleration, as the velocity is
constant, the trajectory is for all $\sigma_{\theta}$ the same.\\
Concerning the angle, the more we raise $\sigma_{\theta}$ the higher the error on the mesured angle is.

\item varying $\sigma_a$ with $\sigma_\theta=0$
\begin{center}
\includegraphics[width=0.66\textwidth]{img/q2_2.eps}
\end{center}
The more the noise on the acceleration increases, the more the trajectory is impacted. \\
In this case, the bearing is also impacted, it seems logical as one has changed the state equations :
the noise on the acceleration does change the relative position, therefore modyfing the true bearing. \\
From these comments, one could explain the situation stating that $\sigma_a$ represents the change of 
acceleration of the target, that can not be predicted. The change of acceleration induces a change
of position, therefrom a change on the bearing.


\item varying $\sigma_\theta$ proportionaly to $\sigma_a$
\begin{center}
\includegraphics[width=0.66\textwidth]{img/q2_3.eps}
\end{center}
The higher $\sigma_a$ is set, the quicker the relative distance augments. Taking a look at the bearing,
        we observe two trends: a slow (low frequency) variation, due to the acceleration of the target
         (which is integrated twice to get the bearing, therefore the variations are slow), and 
         a high frequency variation due to the measurement errors (that are adding a white noise).

\item  Keeping $\sigma_\theta$ and $\sigma_a$ constant

\begin{center}
 \includegraphics[width=0.66\textwidth]{img/q2_4.eps}
\end{center}
When $\sigma_a=0.5$ we observe that the target motion changes reasonably slowly, and
with $\sigma_{\theta}=0.1$ the mesurement noise is not adding too much uncertainty on the bearing. \\
With three simulations, one observes the randomness of the process.
\end{itemize}



%Q3
\chapter{Building a sequential Monte Carlo algorithm}
\section*{Code}
For all the methods that use a Monte Carlo algorithm, one built a general function 
\texttt{particle\_filter.m}, based on the reference document given in the statement
\footnote{A. Srivastava. Computational methods in statistics. Florida State University, 2009.
\url{http://stat.fsu.edu/~anuj/pdf/classes/CompStatII10/BOOK.pdf}}.\\
\lstinputlisting[caption={General Monte Carlo algorithm},label={MonteCarlo}]{../matlab/particle_filter.m}
The main code used here is the function \texttt{q3.m} (to employ it with the proper
parameters, plot and save the results one can launch the script \texttt{plot\_q3.m}).
\newpage
\lstinputlisting[caption={Comparing the results with Monte Carlo algorithm and the model}]{../matlab/q3.m}
\section*{Results}
By ploting the histograms of the distribution of the points used in the Monte Carlo algorithm, 
with $\sigma_a=0.1$ and $\sigma_{\theta}=0.1$, at the beginning (k=1) one has a look alike gaussian
distibution for both the X position and Y position. The more k augments, the less the
distribution looks like a gaussian and the wider is its variance (1 when k=1, to 50 for k=200).
This indicates that the quality of the estimation decreases when $k$ augments.

\begin{center}
   \includegraphics[width=0.49\textwidth]{img/q3_hist_1.eps}
   \includegraphics[width=0.49\textwidth]{img/q3_hist_50.eps}
   \includegraphics[width=0.49\textwidth]{img/q3_hist_100.eps}
   \includegraphics[width=0.49\textwidth]{img/q3_hist_200.eps}
\end{center}


\begin{center}
	\begin{minipage}{.6\textwidth}
		\includegraphics[width=0.95\textwidth]{img/q3_path.eps}
	\end{minipage}%
	\begin{minipage}{.4\textwidth}
		Plotting the real vs. the estimated position and indicating with dots the (X,Y) of the 
		herein produced histograms (k=1,50,100,200), one sees that the more $k$ augments
		the further the estimation is from the real position. The bearing is measured at each step (with a small error) and
		one can check that the result on the angle is convincing. Yet concerning the distance the measures don't bring
		much relevant information. What helps the best is the variability of the bearing, yet it is not enough. For this
		reason the distance is quite approximative.
	\end{minipage}
\end{center}

%Q4
\chapter{Applying the Monte Carlo algorithm to an artificial submarine 
tracking problem}
\section*{Code}

As the fourth and fifth questions are both established on applying the algorithm~\ref{MonteCarlo}
to the submarine tracking problem, one decided to group the main code for questions 4 and 5
in the function \texttt{q4q5.m}.\\
\lstinputlisting[caption={The artificial submarine tracking problem initialised with 'data.m'},label={q4q5}]{../matlab/q4q5.m}
To call \texttt{q4q5} in the present case, one should use \texttt{q4.m} (to use it with the proper parameters,
plot and save the results one can launch the script \texttt{plot\_q4.m}).\\
\lstinputlisting[caption={Question 4}]{../matlab/q4.m}

\section*{Results}
To introduce the results, one uses the following legends\\

	\begin{minipage}{.5\textwidth}
		\flushleft For the positions :\\
		 \center\includegraphics[width=4cm]{img/q4_legend1.png}
	\end{minipage}%
	\begin{minipage}{.3\textwidth}
		For the velocities :\\
		 \center\includegraphics[width=4cm]{img/q4_legend2.png}
	\end{minipage}

\begin{itemize}
\item $k=1$\\
The distribution of the velocity particles corresponds to the initial distribution ($k=0$) : as one doesn't have yet 2 measures 
of position of the target, it cannot estimate properly the velocity, the clouds have a large scope.\\
Concerning the cloud of position particles, as one doesn't know the distance but only the bearing, it forms a shape
that is close to a line. One can easily check by extending the "line" to the initial position of the observer that it 
follows the bearing.\\
There is no big difference between the pre resampling and the post-resampling because the initial distribution already corresponds
to the observation that is made.\\
The position and the velocity clouds are not influenced one by another : they mainly depend of the distributions that were
used to generate them at the begininng.

\item $k=2$\\
The pre-resampling position is now affected by the velocity cloud of the previous step : each pre-resampling particle position
at $k=2$ is equal to the positon at $k=1$ to which is added the velocity at $k=1$ times the time step, therefrom the cloud forms
a circle-shape. As one knows the bearing (with a small error indeed), the observations makes the post-resampling cloud
in a shape that is again close to a line. Compared to $k=1$ the scope of the line is narrowed. \\
As for the velocity clouds, the pre-resampling is close to the post-resampling at $k=1$. Now that one disposes of two positions,
the velocity can be better identified : the cloud is shrinked. \\
At this step, velocity and position have affected one another.






\begin{center}
	\begin{minipage}{.5\textwidth}
		 \includegraphics[width=.98\textwidth]{img/q4_1.png}
	\end{minipage}%
	\begin{minipage}{.5\textwidth}
		\includegraphics[width=0.98\textwidth]{img/q4_2.png}
	\end{minipage}
\end{center}
\item $k=3$\\
Concerning the position, one can observe that the post-resampling cloud is translated following the course of the target compared
to the pre-resampling cloud. Also, the bearing is increasing.\\
As for the velocity, the particle cloud stays narrow for both the pre and post-resampling.

\item $k=15$\\
The position of the observer is especial : it has just changed its direction. Concerning the bearing,
it has changed sign. The clouds are properly oriented, in accordance with the bearing.\\
The velocity clouds are converging : compared to $k=3$ the range of the particles is divided by a factor of order 10.

  \begin{center}
	\begin{minipage}{.5\textwidth}
   		\includegraphics[width=0.98\textwidth]{img/q4_3.png}
	\end{minipage}%
	\begin{minipage}{.5\textwidth}
		 \includegraphics[width=0.98\textwidth]{img/q4_15.png}
	\end{minipage}
\end{center}
\item $k=26$\\
In the end, one still has a line shape for the pre and post-resampling clouds, its length hasn't much decreased
since $k=3$. This is still due to the fact that one has the observation on the bearing but not on the distance.
Hence the bearing is still correct.\\
Since $k=15$, there hasn't been any improvement in the range of the velocity clouds.

  \begin{center}
		 \includegraphics[width=0.5\textwidth]{img/q4_26.png}
\end{center}
  

\end{itemize} 

%Q5
\chapter{Improving the results using a post-regularised sequential Monte Carlo method}
\section*{Code}
As the fourth and fifth questions are both established on applying the algorithm~\ref{MonteCarlo}
to the submarine tracking problem, one decided to group the main code for questions 4 and 5
in the function \texttt{q4q5.m}.\\
To call \texttt{q4q5} \ref{q4q5} in the present case, one should use \texttt{q51.m} and \texttt{q52.m} 
(to use it with the proper parameters, plot and save the results one can simply launch the script \texttt{plot\_q5.m}).\\
\lstinputlisting[caption={}]{../matlab/q51.m}
\lstinputlisting[caption={Question 5}]{../matlab/q52.m}
\section*{Results}
\begin{itemize}
\item Using the particle filter created previously\\
Due to the conception of the filter, changing of the number of particles can only happen when resampling the set (ligne 57 of
\ref{MonteCarlo}). As it asked to set $\sigma_a$ to zero, there is no change in the velocity and the process noise $\epsilon_k$ 
is equal to zero. Also, the change of bearing is small. Therefore, at this step,  the diversity of the particles can only decrease.
The effective number of particles is thus decreasing. One then looses the advantage of the Monte Carlo algorithm, based on
the Law of Large Numbers.\\
\begin{center}
 \includegraphics[width=0.66\textwidth]{img/q51.eps}
\end{center}
Taking a look at the results, one sees that the number of effective particles decreases exponentially with the number of steps.
This brings an error on the estimation of the target's position : the last three positions are off track whilst the previous three
were quite correct.

\item Using a regularized particle filter\\
By adding some noise in the resampling when necessary (the effective number of particles is too low based on a criterion
given in the statement), one can keep the number of effective particles sufficiently high.
\begin{center}
\includegraphics[width=0.66\textwidth]{img/q52.eps}
\end{center}
%TODO je ne sais pas quoi mettre (ptetr qu il n y a rien a mettre...) et je m endors car finalement je n ai pas bu de cafe... argh! je stoppe ici ;)
\end{itemize}
%Q6
\chapter{Analysing the error of the estimation}
\section*{Code}
One develops the Carmér-Rao lower bound and then the root mean square error for the submarine-tracking problem, using the
preceding codes :
\lstinputlisting[caption={Question 6}]{../matlab/q6.m}

\section*{Results}
\begin{center}
   \includegraphics[width=0.92\textwidth]{img/q6.png}
\end{center}

At first, one finds that the experimental error (root mean square, RMS) is higher than the lower bound (Carmér-Rao lower bound,
CRLB), they approximately follow the same course. They both diminish over time, meaning that the estimation converges towards a low variance. These results
 are promising.\\

Taking a closer look at the CRLB, at the begining the variance tends to augment because the observations do not have much
influence on the position (the bearing is close to constant, the acceleration close to zero). Starting at $k=6$, the change
of relative position is sufficient for the bearing to change more significantly, the variance then decreases.
When $k=15$, the observer makes a significant change of direction ; this gives information on the position of the
target, diminishing the variance ;  the CRLB diminishes substantially. In the end, after $k=15$, the change of bearing is again
close to constant and the acceleration close to zero, there is not enough noise in the system and as a result the CRLB augments
again.

From this, one can state that the quality of the estimation depends on two antagonistic effects : 
\begin{itemize}
\item adding entropy to the system by adding noise on the acceleration. This allows to get information and therefore
augment the precision;
\item when the new measures do not bring round enough new information, they are redundant and then the precision
diminishes.
\end{itemize}
The fact that one effect induces the other and vice versa allows the estimation to stay close to the reality : it is never perfect but
it never gets too far.\\

As a suggestion of improvement, one could add the number of particles in the system. It was asked to set it to 5000, 
by augmenting it we'd have to make more calculations but the variety of particle (the number of non redudant particles)
would stay higher, therefore enhancing the estimation.



\end{document}
